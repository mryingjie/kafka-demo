1、kafka中的几个概念：
    （1）producer：数据生产者
    （2）consumer：数据消费者
    （3）broker：保存数据的进程 每台服务器上都有独立的broker进程，kafka的消息默认保存7天
    （4）topic：数据的分类（目的，主题）用来区分每一类的消息
    （5）partition：数据的分片，每个分片都有对应的副本 一般设置为3个副本。
    （6）group：消费者的逻辑分组 同一组的消费者对同一个topic下的某个消息的消费具有竞争关系，即只能有一个这个组中的消费者消费这个消息。这个消息可以由不同组的消费者分别消费并互不影响
    （7）offset：每个消息都有对应的唯一递增offset，存储的位置根据选用的kafka api不同而不同，一个分组中的所有消费者根据这个值来确定这条消息是否已经消费过；

2、几个问题：
    （1）partition分片数与一组消费者中的消费者个数之间有什么关系：
        kafka的消费端有一个均衡算法，算法如下：
        1.A=(partition数量/同分组消费者总个数)
        2.M=对上面所得到的A值小数点第一位向上取整
        3.计算出该消费者拉取数据的patition合集：Ci = [P(M*i ),P((i + 1) * M -1)]
        因此按照如上的算法有以下结论：
            1>所以如果kafka的消费组需要增加组员，最多增加到和partition数量一致，超过的partition数量的组员只会占用资源，而不起作用；
            2>kafka的partition的个数一定要大于消费组组员的个数，并且partition的个数对于消费组组员取模一定要为0即partition的个数一定要是消费者组员个数的整数倍，不然有些消费者会占用资源却不起作用；
            3>如果需要增加消费组的组员个数，那么也需要根据上面的算法，调整partition的个数;
    （2）partition副本放置策略和broker的关系：
        Kafka分配Replica的算法如下(注意!!! 下面的broker、partition副本数这些编号都是从1开始编号的)：
　　　　将所有存活的N个Brokers和待分配的Partition排序
　　　　将第i个Partition分配到第(i mod n)个Broker上，这个Partition的第一个Replica存在于这个分配的Broker上，并且会作为partition的优先副本( 这里就基本说明了一个topic的partition在集群上的大致分布情况 )
　　　　将第i个Partition的第j个Replica分配到第((i + j) mod n)个Broker上
    （3）如何保证消费者消费的数据是有序的，即消息全局有序
        1>生产者是集群模式，需要一个全局序号管理器
        2>broker分片数量partition设置为1
        3>消费者只能是一个线程，并且需要定义一个数据结构来排序。
        综上，这样做将破坏kafka的高并发性能。因此消息全局有序是做不到的或者说做得到但是没有意义。
    （4）如何保证数据的完全生产即保证数据生产成功
        通过ack机制 设置request.required.acks 决定发送数据是否需要服务器的反馈 三个值0 1 -1
         * 0 表示producer永远不会等待一个来自broker的ack
         * 1 表示在leader replica收到数据后 就会返回ack 但是如果刚写到leader 还没写到replica上就挂掉了 数据可能丢失
         * -1 表示所有的副本都收到数据了才会返回ack
         默认是 1
    （5）消费者如何保存消费状态即offset
        kafka消费者在会保存其消费的进度，也就是offset，存储的位置根据选用的kafka api不同而不同
        消费者如果是根据javaapi来消费，也就是【kafka.javaapi.consumer.ConsumerConnector】，通过配置参数【zookeeper.connect】来消费。这种情况下，消费者的offset会更新到zookeeper上
        如果是根据kafka默认的api来消费，即【org.apache.kafka.clients.consumer.KafkaConsumer】，我们会配置参数【bootstrap.servers】来消费。而其消费者的offset会更新到一个kafka自带的topic【__consumer_offsets】下面，查看当前group的消费进度，则要依靠kafka自带的工具【kafka-consumer-offset-checker】
    （6）kafka和其它分布式消息组件相比有什么特点比如RabbitMQ RocketMQ
        RabbitMQ:
        　　单机吞吐量：万级
        　　topic数量对吞吐量的影响：
        　　时效性：微秒级，延时低是一大特点。
        　　可用性：高，基于主从架构实现高可用性
        　　消息可靠性：
        　　功能支持：基于erlang开发，所以并发能力很强，性能极其好，延时很低
        　　总结：　　
        　　　　erlang语言开发，性能极其好，延时很低；
        　　　　吞吐量到万级，MQ功能比较完备
        　　　　开源提供的管理界面非常棒，用起来很好用
        　　　　社区相对比较活跃，几乎每个月都发布几个版本分
        　　　　在国内一些互联网公司近几年用rabbitmq也比较多一些   但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。
        　　　　erlang开发，很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug。
        　　　　rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。
        RocketMQ:
        　　单机吞吐量：十万级
        　　topic数量对吞吐量的影响：topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降。可支持大量topic是一大优势。
        　　时效性：ms级
        　　可用性：非常高，分布式架构
        　　消息可靠性：经过参数优化配置，消息可以做到0丢失
        　　功能支持：MQ功能较为完善，还是分布式的，扩展性好
        　　总结：
        　　　　接口简单易用，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景
        　　　　而且一个很大的优势在于，源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控
        　　　　社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码
        Kafka:
        　　单机吞吐量：十万级，最大的优点，就是吞吐量高。
        　　topic数量对吞吐量的影响：topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源
        　　时效性：ms级
        　　可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用
        　　消息可靠性：经过参数优化配置，消息可以做到0丢失
        　　功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用
        　　总结：
        　　　　kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展
        　　　　同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量
        　　　　kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略

常用命令：
    1>查看topic
    ./kafka-topics.sh --list --zookeeper hadoop1001:2181
    2>创建topic
    ./kafka-topics.sh --create --topic order --replication-factor 2 --partitions 4 --zookeeper hadoop1002:2181

    3>生产者
    bin/kafka-console-producer.sh --broker-list 192.168.42.121:9092 --topic payment --producer.config config/producer.properties

    4>消费者
    bin/kafka-console-consumer.sh --bootstrap-server hadoop1002:9092 --from-beginning --topic payment


    5>查看topic分区情况
    bin/kafka-topics.sh --describe --zookeeper hadoop1001:2181,hadoop1002:2181,hadoop1003:2181 --topic test

    6>删除topic
    bin/kafka-topics.sh --delete --zookeeper hadoop1001:2181,hadoop1002:2181,hadoop1003:2181  --topic reconcile